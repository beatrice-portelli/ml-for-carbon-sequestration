{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b4cb8-f146-48cc-8f80-5b4f9422c958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, LeaveOneOut\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "\n",
    "def normalized_root_mean_squared_error(y_true, y_pred, norm_factor=None):\n",
    "    if norm_factor is None:\n",
    "        assert False, \"Set norm_factor (for example the average target value for the training set)\"\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    return (rmse / norm_factor)*100\n",
    "\n",
    "model2paper = {\n",
    "    'CatBoostRegressor':         \"CatBoost\",\n",
    "    'GradientBoostingRegressor': \"GBDT\",\n",
    "    'KNeighborsRegressor':       \"KNN\",\n",
    "    'MLPRegressor':              \"MLP\",\n",
    "    'RandomForestRegressor':     \"RF\",\n",
    "    'SVR':                       \"SVR\",\n",
    "    'XGBRegressor':              \"XGBoost\",\n",
    "}\n",
    "\n",
    "from configs import *\n",
    "from experiments_to_run import MODELS, CONFIGS, TARGETS\n",
    "\n",
    "if not os.path.exists(\"../results\"):\n",
    "    os.makedirs(\"../results\")\n",
    "if not os.path.exists(\"../figures_and_tables\"):\n",
    "    os.makedirs(\"../figures_and_tables\")\n",
    "\n",
    "OVERWRITE = True\n",
    "\n",
    "total_iterations = len(MODELS)*len(CONFIGS)*len(TARGETS)\n",
    "curr_iteration = 0\n",
    "\n",
    "for MODEL in MODELS[:1]:\n",
    "    for CONFIG in CONFIGS[:1]:\n",
    "        for TARGET in TARGETS:\n",
    "            \n",
    "            curr_iteration+=1\n",
    "            print(f\"---------------- [{curr_iteration} / {total_iterations}]\")\n",
    "            \n",
    "            if not OVERWRITE:\n",
    "                conf = f\"{TARGET}--{CONFIG.name}--{model2paper[MODEL[0](_).__class__.__name__]}\"\n",
    "                save_path = f\"../results/metrics--{conf}.pickle\"\n",
    "                if os.path.exists(save_path):\n",
    "                    print(\"File already exists. Skipping\", conf)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Running\", conf)\n",
    "\n",
    "            # fixing random seed as soon as possible\n",
    "            # for reproducibility\n",
    "            np.random.seed(123)\n",
    "            random.seed(123)\n",
    "\n",
    "            df = pd.read_csv(\"../data.csv\")\n",
    "            X = df[CONFIG.features]\n",
    "            y = df[TARGET]\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "            model_class, param_distributions, search_cv_args = MODEL\n",
    "            \n",
    "            if param_distributions is None:\n",
    "                \n",
    "                regressor = model_class(_)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                search_cv = RandomizedSearchCV(\n",
    "                    model_class(_), param_distributions=param_distributions,\n",
    "                    scoring=\"neg_mean_squared_error\", random_state=0, **search_cv_args\n",
    "                )\n",
    "                search_cv.fit(X_train.values, y_train.values)\n",
    "\n",
    "                print(\"The best hyperparameters are \",search_cv.best_params_)\n",
    "                \n",
    "                if type(search_cv.estimator) not in [\n",
    "                    KNeighborsRegressor,\n",
    "                    SVR\n",
    "                ]:\n",
    "                    regressor = model_class(_).set_params( # use search_cv.estimator, to make it independent from the estimator's class\n",
    "                        random_state=0,           # fixed random state\n",
    "                        **search_cv.best_params_, # pass all parameters without to need to manually assign them\n",
    "                    )\n",
    "                else:\n",
    "                    regressor = model_class(_).set_params( # use search_cv.estimator, to make it independent from the estimator's class\n",
    "                        **search_cv.best_params_, # pass all parameters without to need to manually assign them\n",
    "                    )\n",
    "\n",
    "            data = []\n",
    "            \n",
    "            # =================================================================\n",
    "            # the following code is an alternative, to split the dataset in\n",
    "            # 66/33 random train/test splits for 10 times to run the evaluation\n",
    "            \n",
    "            folds = []\n",
    "\n",
    "            for random_state in range(10):\n",
    "                cv = KFold(n_splits=3, random_state=random_state, shuffle=True)\n",
    "                tmp_folds = cv.split(X)\n",
    "                folds.append(next(tmp_folds))\n",
    "                \n",
    "\n",
    "            for i, (train_index, test_index) in enumerate(folds):\n",
    "\n",
    "                X_train = X.iloc[train_index]\n",
    "                y_train = y.iloc[train_index].values\n",
    "\n",
    "                X_test = X.iloc[test_index]\n",
    "                y_test = y.iloc[test_index].values\n",
    "\n",
    "                regressor.fit(X_train.values, y_train)\n",
    "                y_pred = regressor.predict(X_test.values)\n",
    "\n",
    "                data.append({\n",
    "                    \"target\": TARGET,\n",
    "                    \"config\": CONFIG.name,\n",
    "                    \"model_name\": regressor.__class__.__name__,\n",
    "                    \"model\": model2paper[regressor.__class__.__name__],\n",
    "                    \"hyperparams\": None if param_distributions is None else search_cv.best_params_,\n",
    "                    \"fold\": i,\n",
    "                    \"X_train\": X_train,\n",
    "                    \"y_train\": y_train,\n",
    "                    \"X_test\": X_test,\n",
    "                    \"y_test\": y_test,\n",
    "                    \"y_pred\": y_pred,\n",
    "                    \"model_obj\": deepcopy(regressor),\n",
    "                })\n",
    "\n",
    "            data = pd.DataFrame(data)\n",
    "            save_path = f\"../results/predictions--{TARGET}--{CONFIG.name}--{model2paper[regressor.__class__.__name__]}.pickle\"\n",
    "            data.to_pickle(save_path)\n",
    "            # print(\"predictions saved to\", save_path)\n",
    "            # display(data)\n",
    "            \n",
    "            tmp = data\n",
    "            y_test = pd.concat(\n",
    "                [x for (i,x) in tmp[[\"fold\",\"y_test\"]].explode(column=\"y_test\").groupby(\"fold\")],\n",
    "                axis=0\n",
    "            ).reset_index(drop=True)\n",
    "            y_pred = pd.concat(\n",
    "                [x for (i,x) in tmp[[\"fold\",\"y_pred\"]].explode(column=\"y_pred\").groupby(\"fold\")],\n",
    "                axis=0\n",
    "            ).reset_index(drop=True)\n",
    "            test_index = pd.DataFrame(\n",
    "                sum(tmp.X_test.apply(lambda d: d.index.tolist()).values.tolist(), []),\n",
    "                columns=[\"sample_idx\"]\n",
    "            )\n",
    "            tmp2 = pd.concat(( y_test, y_pred[\"y_pred\"], test_index), axis=1)\n",
    "            tmp2.to_csv(save_path.replace(\"pickle\", \"csv\"), index=None)\n",
    "\n",
    "            data[\"MSE\"] = data.apply(lambda row: mean_squared_error(row.y_test, row.y_pred), axis=1)\n",
    "            data[\"R2\"] = data.apply(lambda row: r2_score(row.y_test, row.y_pred), axis=1)\n",
    "            data[\"MAPE\"] = data.apply(lambda row: mean_absolute_percentage_error(row.y_test, row.y_pred), axis=1)\n",
    "            data[\"RMSE\"] = data.apply(lambda row: root_mean_squared_error(row.y_test, row.y_pred), axis=1)\n",
    "            data[\"NRMSE\"] = data.apply(lambda row: normalized_root_mean_squared_error(row.y_test, row.y_pred, norm_factor=row.y_train.mean()), axis=1)\n",
    "\n",
    "            data = data.drop(columns=[\"X_train\", \"y_train\", \"X_test\", \"y_test\", \"y_pred\"])\n",
    "            save_path = f\"../results/metrics--{TARGET}--{CONFIG.name}--{model2paper[regressor.__class__.__name__]}.pickle\"\n",
    "            data.to_pickle(save_path)\n",
    "            print(\"metrics, predictions and models saved to\\n\", save_path)\n",
    "            # display(data)\n",
    "\n",
    "            for metric in [\"R2\", \"MAPE\", \"RMSE\", \"NRMSE\"]:\n",
    "\n",
    "                print(f\"{metric:>10} {data[metric].mean().round(2):>7} Â± {data[metric].std().round(2):>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea917f79-fcad-4c1e-9aeb-47dfddce7733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "if os.path.exists(\"catboost_info\"):\n",
    "    shutil.rmtree(\"catboost_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26af98-8c38-41cf-b6db-a352488baccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bp_base",
   "language": "python",
   "name": "bp_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
