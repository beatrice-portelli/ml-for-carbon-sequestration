{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31b4cb8-f146-48cc-8f80-5b4f9422c958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"tensorflow\").addHandler(logging.NullHandler(logging.ERROR))\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, LeaveOneOut\n",
    "from sklearn.linear_model import (Ridge, BayesianRidge)\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return mean_squared_error(y_true, y_pred, squared=False)\n",
    "\n",
    "\n",
    "def normalized_root_mean_squared_error(y_true, y_pred, norm_factor=None):\n",
    "    if norm_factor is None:\n",
    "        assert False, \"Set norm_factor (for example the average target value for the training set)\"\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    return (rmse / norm_factor)*100\n",
    "\n",
    "model2paper = {\n",
    "    # 'KerasRegressor': \"1D-CNN\",\n",
    "    # =========================================\n",
    "    'CatBoostRegressor':         \"CatBoost\",\n",
    "    'GradientBoostingRegressor': \"GBDT\",\n",
    "    'KNeighborsRegressor':       \"KNN\",\n",
    "    'MLPRegressor':              \"MLP\",\n",
    "    'RandomForestRegressor':     \"RF\",\n",
    "    'SVR':                       \"SVR\",\n",
    "    'XGBRegressor':              \"XGBoost\",\n",
    "    # =========================================\n",
    "    \"GaussianProcessRegressor\": \"GaussProc\",\n",
    "    \"BayesianRidge\": \"BayesianNN\",\n",
    "    \"StackingRegressor\": \"StackEns\",\n",
    "    \"LGBMRegressor\": \"LightGBM\",\n",
    "    \"AdaBoostRegressor\": \"AdaBoost\",\n",
    "    \"BaggingRegressor\": \"BaggedDT\",\n",
    "}\n",
    "\n",
    "from configs import *\n",
    "from experiments_to_run import MODELS, CONFIGS, TARGETS\n",
    "random.seed(123)\n",
    "\n",
    "\n",
    "# ============== spatial clustering, 10 clusters, TRAINING [start]\n",
    "cluster_df = pd.read_csv(\"../spatial_clusters_10.csv\")\n",
    "\n",
    "tmp_test_folds = []\n",
    "test_folds = []\n",
    "train_folds = []\n",
    "\n",
    "for cluster_idx, data in cluster_df.groupby(\"cluster\"):\n",
    "    tmp_test_folds.append(data.index.tolist())\n",
    "\n",
    "random.shuffle(tmp_test_folds)\n",
    "for i in range(5):\n",
    "    test_folds.append(tmp_test_folds[i*2]+tmp_test_folds[i*2+1])\n",
    "    train_folds.append(\n",
    "        list(set(cluster_df.index.tolist())-set(test_folds[-1]))\n",
    "    )\n",
    "    \n",
    "[random.shuffle(x) for x in test_folds]\n",
    "[random.shuffle(x) for x in train_folds]\n",
    "# ============== spatial clustering, 10 clusters, TRAINING [end]\n",
    "\n",
    "# ============== spatial clustering, 10 clusters, VALIDATION [start]\n",
    "tuning_test_folds = []\n",
    "tuning_train_folds = []\n",
    "\n",
    "random.shuffle(tmp_test_folds)\n",
    "for i in range(5):\n",
    "    tuning_test_folds.append(tmp_test_folds[i*2]+tmp_test_folds[i*2+1])\n",
    "    tuning_train_folds.append(\n",
    "        list(set(cluster_df.index.tolist())-set(tuning_test_folds[-1]))\n",
    "    )\n",
    "    \n",
    "[random.shuffle(x) for x in tuning_test_folds]\n",
    "[random.shuffle(x) for x in tuning_train_folds]\n",
    "# ============== patial clustering, 10 clusters, VALIDATION [end]\n",
    "\n",
    "\n",
    "if not os.path.exists(\"../results\"):\n",
    "    os.makedirs(\"../results\")\n",
    "if not os.path.exists(\"../figures_and_tables\"):\n",
    "    os.makedirs(\"../figures_and_tables\")\n",
    "\n",
    "OVERWRITE = False\n",
    "\n",
    "total_iterations = len(MODELS)*len(CONFIGS)*len(TARGETS)\n",
    "curr_iteration = 0\n",
    "\n",
    "for MODEL in MODELS:\n",
    "    for CONFIG in CONFIGS:\n",
    "        for TARGET in TARGETS:\n",
    "            \n",
    "            curr_iteration+=1\n",
    "            print(f\"---------------- [{curr_iteration} / {total_iterations}]\")\n",
    "            \n",
    "            if not OVERWRITE:\n",
    "                conf = f\"{TARGET}--{CONFIG.name}--{model2paper[MODEL[0](_).__class__.__name__]}\"\n",
    "                save_path = f\"../results/metrics--{conf}.pickle\"\n",
    "                if os.path.exists(save_path):\n",
    "                    print(\"File already exists. Skipping\", conf)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"Running\", conf)\n",
    "\n",
    "            # fixing random seed as soon as possible\n",
    "            # for reproducibility\n",
    "            np.random.seed(123)\n",
    "            random.seed(123)\n",
    "\n",
    "            df = pd.read_csv(\"../data.csv\")\n",
    "            X = df[CONFIG.features]\n",
    "            y = df[TARGET]\n",
    "\n",
    "            model_class, param_distributions, search_cv_args = MODEL\n",
    "            if type(model_class(_)) == KerasRegressor:\n",
    "                print(X.shape)\n",
    "                param_distributions[\"num_features\"] = [X.shape[1]]\n",
    "            \n",
    "            if param_distributions is None:\n",
    "                \n",
    "                regressor = model_class(_)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                search_cv = RandomizedSearchCV(\n",
    "                    model_class(_),\n",
    "                    param_distributions=param_distributions,\n",
    "                    scoring=\"neg_mean_squared_error\",\n",
    "                    random_state=0,\n",
    "                    # load the fold with spatial blocking\n",
    "                    cv=zip(tuning_train_folds, tuning_test_folds),\n",
    "                    n_jobs=-1,\n",
    "                    n_iter=30,\n",
    "                    return_train_score=True,\n",
    "                    **search_cv_args\n",
    "                )\n",
    "                search_cv.fit(X.values, y.values)\n",
    "\n",
    "                print(\"The best hyperparameters are \",search_cv.best_params_)\n",
    "                print(\"The best score is \",search_cv.best_score_)\n",
    "                \n",
    "                if type(search_cv.estimator) not in [\n",
    "                    KNeighborsRegressor,\n",
    "                    SVR,\n",
    "                    StackingRegressor,\n",
    "                    BayesianRidge,\n",
    "                    KerasRegressor,\n",
    "                ]:\n",
    "                    # use search_cv.estimator, to make it independent from the estimator's class\n",
    "                    regressor = model_class(_).set_params(\n",
    "                        # fixed random state\n",
    "                        random_state=0,\n",
    "                        # pass all parameters without to need to manually assign them\n",
    "                        **search_cv.best_params_,\n",
    "                    )\n",
    "                else:\n",
    "                    # use search_cv.estimator, to make it independent from the estimator's class\n",
    "                    regressor = model_class(_).set_params(\n",
    "                        # pass all parameters without to need to manually assign them\n",
    "                        **search_cv.best_params_, \n",
    "                    )\n",
    "\n",
    "            data = []\n",
    "            \n",
    "\n",
    "            # =================================================================\n",
    "            # 5-fold cross validation\n",
    "            \n",
    "            folds = zip(train_folds, test_folds)\n",
    "\n",
    "            for i, (train_index, test_index) in enumerate(folds):\n",
    "\n",
    "                X_train = X.iloc[train_index]\n",
    "                y_train = y.iloc[train_index].values\n",
    "\n",
    "                X_test = X.iloc[test_index]\n",
    "                y_test = y.iloc[test_index].values\n",
    "\n",
    "                regressor.fit(X_train.values, y_train)\n",
    "                y_pred = regressor.predict(X_test.values)\n",
    "                y_pred_train = regressor.predict(X_train.values)\n",
    "\n",
    "                data.append({\n",
    "                    \"target\": TARGET,\n",
    "                    \"config\": CONFIG.name,\n",
    "                    \"model_name\": regressor.__class__.__name__,\n",
    "                    \"model\": model2paper[regressor.__class__.__name__],\n",
    "                    \"hyperparams\": None if param_distributions is None else search_cv.best_params_,\n",
    "                    \"fold\": i,\n",
    "                    \"X_train\": X_train,\n",
    "                    \"y_train\": y_train,\n",
    "                    \"X_test\": X_test,\n",
    "                    \"y_test\": y_test,\n",
    "                    \"y_pred\": y_pred,\n",
    "                    \"y_pred_train\": y_pred_train,\n",
    "                    \"model_obj\": deepcopy(regressor),\n",
    "                })\n",
    "\n",
    "            data = pd.DataFrame(data)\n",
    "            save_path = f\"../results/predictions--{TARGET}--{CONFIG.name}--{model2paper[regressor.__class__.__name__]}.pickle\"\n",
    "            data.to_pickle(save_path)\n",
    "            # print(\"predictions saved to\", save_path)\n",
    "            # display(data)\n",
    "            \n",
    "            tmp = data\n",
    "            y_test = pd.concat(\n",
    "                [x for (i,x) in tmp[[\"fold\",\"y_test\"]].explode(column=\"y_test\").groupby(\"fold\")],\n",
    "                axis=0\n",
    "            ).reset_index(drop=True)\n",
    "            y_pred = pd.concat(\n",
    "                [x for (i,x) in tmp[[\"fold\",\"y_pred\"]].explode(column=\"y_pred\").groupby(\"fold\")],\n",
    "                axis=0\n",
    "            ).reset_index(drop=True)\n",
    "            \n",
    "            y_train = pd.concat(\n",
    "                [x for (i,x) in tmp[[\"fold\",\"y_train\"]].explode(column=\"y_train\").groupby(\"fold\")],\n",
    "                axis=0\n",
    "            ).reset_index(drop=True)\n",
    "            y_pred_train = pd.concat(\n",
    "                [x for (i,x) in tmp[[\"fold\",\"y_pred_train\"]].explode(column=\"y_pred_train\").groupby(\"fold\")],\n",
    "                axis=0\n",
    "            ).reset_index(drop=True)\n",
    "            \n",
    "            test_index = pd.DataFrame(\n",
    "                sum(tmp.X_test.apply(lambda d: d.index.tolist()).values.tolist(), []),\n",
    "                columns=[\"sample_idx\"]\n",
    "            )\n",
    "            train_index = pd.DataFrame(\n",
    "                sum(tmp.X_train.apply(lambda d: d.index.tolist()).values.tolist(), []),\n",
    "                columns=[\"sample_idx\"]\n",
    "            )\n",
    "            \n",
    "            tmp2 = pd.concat(( y_test, y_pred[\"y_pred\"], test_index), axis=1)\n",
    "            tmp2.to_csv(save_path.replace(\"pickle\", \"csv\").replace(\"predictions\", \"predictions_test\"), index=None)\n",
    "            \n",
    "            tmp2 = pd.concat(( y_train, y_pred_train[\"y_pred_train\"], train_index), axis=1)\n",
    "            tmp2.to_csv(save_path.replace(\"pickle\", \"csv\").replace(\"predictions\", \"predictions_train\"), index=None)\n",
    "\n",
    "            data[\"MSE\"] = data.apply(lambda row: mean_squared_error(row.y_test, row.y_pred), axis=1)\n",
    "            data[\"R2\"] = data.apply(lambda row: r2_score(row.y_test, row.y_pred), axis=1)\n",
    "            data[\"MAPE\"] = data.apply(lambda row: mean_absolute_percentage_error(row.y_test, row.y_pred), axis=1)\n",
    "            data[\"RMSE\"] = data.apply(lambda row: root_mean_squared_error(row.y_test, row.y_pred), axis=1)\n",
    "            data[\"NRMSE\"] = data.apply(lambda row: normalized_root_mean_squared_error(row.y_test, row.y_pred, norm_factor=row.y_train.mean()), axis=1)\n",
    "            \n",
    "            data[\"MSE_train\"] = data.apply(lambda row: mean_squared_error(row.y_train, row.y_pred_train), axis=1)\n",
    "            data[\"R2_train\"] = data.apply(lambda row: r2_score(row.y_train, row.y_pred_train), axis=1)\n",
    "            data[\"MAPE_train\"] = data.apply(lambda row: mean_absolute_percentage_error(row.y_train, row.y_pred_train), axis=1)\n",
    "            data[\"RMSE_train\"] = data.apply(lambda row: root_mean_squared_error(row.y_train, row.y_pred_train), axis=1)\n",
    "            data[\"NRMSE_train\"] = data.apply(lambda row: normalized_root_mean_squared_error(row.y_train, row.y_pred_train, norm_factor=row.y_train.mean()), axis=1)\n",
    "\n",
    "            data = data.drop(columns=[\"X_train\", \"y_train\", \"X_test\", \"y_test\", \"y_pred\", \"y_pred_train\"])\n",
    "            save_path = f\"../results/metrics--{TARGET}--{CONFIG.name}--{model2paper[regressor.__class__.__name__]}.pickle\"\n",
    "            data.to_pickle(save_path)\n",
    "            print(\"metrics, predictions and models saved to\\n\", save_path)\n",
    "            # display(data)\n",
    "\n",
    "            for metric in [\"R2\", \"MAPE\", \"RMSE\", \"NRMSE\"]:\n",
    "\n",
    "                print(f\"{metric:>10} {data[metric].mean().round(2):>7} ± {data[metric].std().round(2):>5}  {data[metric+'_train'].mean().round(2):>7} ± {data[metric+'_train'].std().round(2):>5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea917f79-fcad-4c1e-9aeb-47dfddce7733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "if os.path.exists(\"catboost_info\"):\n",
    "    shutil.rmtree(\"catboost_info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c04218f-329f-4671-a994-50cbb0b516cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bp_base",
   "language": "python",
   "name": "bp_base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
